{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basic Assignment\n",
    "## NLP 맛보기 - spam.csv를 가지고 유의미한 해석을 도출해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'Python 3.10.1 64-bit'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m다음 명령어를 실행하여 Python 환경에 'ipykernel'을(를) 설치합니다. \n",
      "\u001b[1;31m 명령: '\"c:/Program Files/Python310/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 불러오기\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "- 보시면 아시다시피 spam.csv는 라벨이 있는 데이터입니다. 물론 7주차 주제가 텍스트 기초인만큼 텍스트만 활용하셔도 되고, 라벨까지 활용하셔서 모델을 돌려보셔도 좋습니다 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.iloc[5]['v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.v1 = spam.v1.replace(['ham','spam'],[0,1])\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   int64 \n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "spam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.drop_duplicates(subset=['v2'], inplace=True)\n",
    "len(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>5567</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>5568</td>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>5569</td>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>5570</td>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>5571</td>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  v1                                                 v2\n",
       "0         0   0  Go until jurong point, crazy.. Available only ...\n",
       "1         1   0                      Ok lar... Joking wif u oni...\n",
       "2         2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         3   0  U dun say so early hor... U c already then say...\n",
       "4         4   0  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...  ..                                                ...\n",
       "5164   5567   1  This is the 2nd time we have tried 2 contact u...\n",
       "5165   5568   0              Will Ì_ b going to esplanade fr home?\n",
       "5166   5569   0  Pity, * was in mood for that. So...any other s...\n",
       "5167   5570   0  The guy did some bitching but I acted like i'd...\n",
       "5168   5571   0                         Rofl. Its true to its name\n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = spam.reset_index()\n",
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='v1'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAADnCAYAAADGrxD1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATMklEQVR4nO3deZgdVZ3G8W91moREtoAswQAViSJhURYRSEgiuCAlEaMP4ggyGgEREEHAAlGaRS0FIdFhFBVhxBEUF0YoBoYtAY0IGSYSUTKyFJAIhPViWPr2cuaPexmbmE7f7r63flXnvp/nuQ9Z+ua85Mnbp6ruqTqBcw4R8UeHdQARaS6VWsQzKrWIZ1RqEc+o1CKeUalFPKNSi3hGpRbxjEot4hmVWsQzKrWIZ1RqEc+o1CKeUalFPKNSi3hGpRbxjEot4hmVWsQzKrWIZ1RqEc+o1CKeUalFPKNSi3hGpRbxjEot4hmVWsQzKrWIZzqtA0jzhXHaCWwHTKm/tgY2HuS1IdALVIHutbyeBR4b8FpR/++qLIm0EVsBBdogr9zCON0GmA7sCkwDdgTeSOu/YXcDjwD3AkuBPwBLsiR6osXjyhBU6hIJ47QD2BmYMeC1jWmof/Qo8Hvgd8BNWRL90ThP21GpCy6M082AQ+qvGcAmhnFG4hHgeiAFbs2S6GXjPN5TqQsojNMtgLnAh4FZ+HPt4xXgNmoFvzpLolXGebykUhdEGKcbA4cDh1KbkX3/ZKIHuA64FLghS6I+4zzeUKmNhXE6DTgBOAJ4nXEcKyuBy4FLsyR62DhL6anUBsI4HQMcTK3M+xvHKRIH3ApckCXRDdZhykqlzlEYpxOAY6mVeTvjOEV3N3BulkTXWgcpG5U6B2Gcrk+tzDGwhXGcslkKnAf8UotdGqNSt1D9MPuTQBe1VV0ycn8EzsmS6GrrIEWnUrdIGKfvB75ObZWXNM8dwGezJFpqHaSoVOomC+N0W+A7wEHWWTzWD/wAOD1LometwxSNSt0kYZwGwHHA14ANjOO0i6eAz2dJdIV1kCJRqZsgjNO3UJs5pltnaVO3AvOyJMqsgxSBSj0K9VscvwB8CRhnHKfdVYCjsyT6mXUQayr1CNXPna8G9rLOIq/xQ2oX0l60DmJFpR6BME7fA/wE2Mw6i6zVcuCwdr1CrlIPQ/1i2JfrL99vuCi7biDOkmi+dZC8qdQNCuN0U+DHwPuss8iwXAF8KkuiqnWQvKjUDQjj9K3ANUBom0RGaCHwwSyJnjfOkQuVeghhnM4ErgU2ss4io3I/cFA73Nqp88J1CON0DnAjKrQP3gLcGcap959WqNSDCOP0SOAXwPrWWaRptgAWhnF6iHWQVlKp1yKM05OAy/Dn2WDyd+OBq8M4nWsdpFVU6jWEcXoecCEQWGeRlukErqrfSecdlXqAME6/DHzROofkYj3g52Gcvtc6SLPp6nddGKcnAvOtc0juXgGiLIlutQ7SLCo1/39R7DJ0yN2uXgIOzJLoDusgzdD2pa4ffl2HLoq1u78B07MkWmYdZLTautRhnO4OLEIPNZCaR4C9yr5zSNteKAvjdCtqM7QKLa/aDviP+tNfS6stS11/yudVwCTrLFI4ewPftQ4xGm1ZauCr1DaeE1mbI8M4Pd46xEi13Tl1fT33NehKt6xbD3BAGa+It1WpwzidAtxD+fZ4FhsrgF3Kdstm2xx+h3E6Dvg5KrQ0bjLwLesQw9U2paZ2Hr27dQgpnSPCOP2gdYjhaIvD7zBO9wTuBMZYZ5FSegrYuSyfX3s/U9efzf0DVGgZuc2BS6xDNMr7UgOnAG+1DiGld0j9HoHC8/rwO4zTqcAy9PQSaY7ngKlF35TP95n6e6jQ0jwTgbOsQwzF25k6jNMjgB9Z5xDv9FK7aLbcOshgvJypwzgdC5xrnUO81Amcbx1iXbwsNXAMtTtuRFrh4DBOD7AOMZhCljoIggODIFgeBMEDQRDEw3lvGKcT0HPGpPUuDOO0kP0pXKggCMYAF1Pbs2oa8NEgCKYN4484EdiyFdlEBtgVKORHXIUrNbX9nh9wzj3knKtSu+/5A428MYzTTYDTWphNZKC4iLN14QIBbwAeG/DzFfVfa8Rp6IYNyc+bgTnWIdZUxFKv7T7nIT93C+N0I6C0N7ZLaZ1qHWBNRSz1CmCbAT+fDPy1gffNAzZsSSKRwe0bxum+1iEGKmKp7wbeFATBlCAIxgKHAb9e1xvq5zUn5BFOZC0KNVsXrtTOuV5qh9E3An8Gfuacu2+Itx0MTGl1NpFBzAnj9M3WIV5VyAfYO+euB64fxls+3aosIg3ooPZR6nHWQcCDtd9hnIbAgxTwqEPaynPApCyJuq2D+FCEo/Dj/0PKbSIF+XjLhzJ8zDqASF0hVpiV+vA7jNM9gCXWOUTqeoGtsiR6xjJE2WfqudYBRAboBD5kHUKlFmmuj1gHKO3hdxin04ChPr8WyVs/sIXlIXiZZ2rN0lJEHcD+1gHKSqWWojJ9KkopSx3G6ebAbtY5RAahUo/AdOsAIuswNYxTs2fklbXUhbrVTWQtzGbrspZaM7UUnUrdqPo+03tY5xAZwjutBi5dqakVepx1CJEhTArj1OSptmUstQ69pSx2thi0jKXe0zqASINU6gYV5rExIkPYxWLQMpZ6e+sAIg0ymalLdUNH/cLDE9Y5RBq0GtgoS6JcS1a2mXqqdQCRYdgACPMeVKUWaa3cl4uq1CKttUXeA5at1G+0DiAyTLkvQClbqbXvtJSNZuohTLQOIDJMKvUQVGopG5V6CJtYBxAZJpV6CBtYBxAZpk3zHnBEpQ6C4N3NDjKUME47gfXyHldklHLfWXakM/WlTU3RmAkGY4qMVu6lHnTAIAh+PdhvAZu1Js46le1UQQRgTN4Druu7yH7A4dQWpQ8UAHu1LNHgzPf99dlPx56z6O3BcpNbBX3WT/BCbevq/Kyr1HcCLznnFq35G0EQLG9dpEG9YjBm2/ho9cwZt4z9/F1TOp7cxzqLTzpwL+Q/5iCcc+9zzt0WBMFJQRBMXuP3ZrY+2mvVb1+r5j1uu+inY8y7qhe8/dH+Le60zuKZnrwHbOQ8dSPgxiAI7giC4LggCCyXamq2bqE+xnTuX71gj5Vus7uss3ikN+8Bhyy1c+5s59xOwHHA1sCiIAhubnmytVOpW6yXzvVmd1/0tsfdpndbZ/FE7v9mh3NFeRW1p448g8EqmbqXjcZtKz10jp3VfdGuq9wmS6yzeCD3J/UMWeogCI4NgmAhcAvweuAo59yurQ42iJeMxm07VdYbt1/3/J2fdhvdY52l5B7Pe8BGZurtgM8553Zyzp3lnPtTq0Otw18Nx2473Yxdf0b3gh2fcRv+j3WWEsv932wj59Sxc25pDlka8ah1gHbzCuPGz+j+1g7PuQ3+YJ2lpAo5UxfJI9YB2tHLjJswo3vB9hU34V7rLCVUvJm6YDRTG3mR8Rvs2/3tKS+48X+0zlIymqmHoFIbepHxG+7b/e1t/+bG32edpUQ0Uw9BpTa2mgkbTe9eMPlFt/6frbOUgKOIH2kVzKPU/qLE0AtssPH07gVbveTGWdwDUCYP01Up5DLRwsiSqBt4yDqHwPNsOHF694LNX3Zj/9c6S4GZLN4pVanrtHyxIJ5jo01ndC/Y9BW33gPWWQrqvy0GLWOptXSxQJ5h49fP7J6/cbfr1BHUP9JM3SDN1AWziombz+qe/7qq63zYOkuBOMBkiW0ZS30P0G8dQl7rCTbdclb3ReOrbowWCNU8SFfleYuBS1fqLIlWA/o4pYAeZ7Ot3tl94dgeN0YfPRqdT0MJS12nQ/CCWsnmkw6oXtDR6zpWWGcxplIP02LrADK4R92Wk99VPd/1uo52vqvO7LFQZS31jdYBZN0yN2mb91S/0dPnOnJf+1wAz2I48ZSy1FkSPYrOqwvvIbf1dgdWk+4+FzxpnSVnKV2VPqvBS1nquv+0DiBD+4ubHB5U/dpLfS54yjpLjgbbCCMXZS71ddYBpDHL3bZTDq5+5YV+FzxtnSUH3cANlgHKXOrbqZ27SAn8yYXbH1I957l+FzxjnaXFbqOrsuauNrkqbamzJOoDrrXOIY27123/prnVs5/udznvQ5Mv00NvKHGp635uHUCGZ6mbusOh1bOecI6KdZYWcKjUo3YDBo+LkdFZ4nbY8bDqmSs9LPYSuiorrUOUutRZEvUCl1nnkOH7vZs27WM9Z6xwjtw3kGuhy60DQMlLXXcpehpKKS3u33mnj/fEjzj3D9sll9GLwI+tQ4AHpc6S6CHgVuscMjJ39O+6yyd7Tn3QOV60zjJKP6WrUoijjtKXuu771gFk5G7r3+2tR/ec/BfnSr2t0iVDfUEQBD8MgmBVEAQtfcyyL6X+FdAOCxu8dVP/nm87tufE+50r5SaIv6er0sj2v5cDB7Y4ix+lzpKoSu3cWkrshv537H5Czwl/co5u6yzDNL+RL3LO5bJgyotS112IdsUsvev699njpJ7PLHOOqnWWBq2gYOslvCl1lkSrgO9Y55DRu6Z/xp6n9R691Dlyf2b2CHybrkqvdYiBvCl13floY3ovXN03e68zeufd4xyFKswaHgf+xTrEmrwqdZZETwLftc4hzXFl3wHvOKv3yLsLXOwuuiqFO+XzqtR130CztTd+1Pfefc7tPeIu5zB76MAg7meYF2eDILgS+B2wQxAEK4IgmNeKYIFz/i3GCuN0PnCidQ5pnmPGXPvbuPPKfYKgMBPRXLoqv7IOsTZF+Qtqtq+A17f3tZ1L+g6efkHvoYudK8Qz3xcXtdDgaamzJHoK+KJ1Dmmui/sOmbGgb+5vnTNf63+a8fjr5GWp6y5B+255Z37vh/f71745vzEs9q/pqvzWaOyGeFvqLIn6gWPRFj3eOb/3sP2+33fQHQZDvwycajDusHhbaoAsiZbQwEJ7KZ+v9h4+87Le9y7Kedgz6KoUfj9ur0tddwawyjqENN/ZvUfO+nHvAXkVexGwIKexRsX7UmdJ9DxwknUOaY0ze+fN+mnvrIUtHmY18Am6KtYX6BrifakBsiT6CXCldQ5pjS/0HjP7l30zFrZwiFPoqpRm7+22KHXdsYD2TvbUyT2fmX1d396tOBT/L7oqpbou0zalzpKoAhwOhVtuKE1yfM9nZ93Yt+fCJv6RFaAlSzlbqW1KDZAl0W+AL1nnkNY5pufk2bf07bawSX/cp+mqlG6f7bYqdV2CNtfz2ryeU2ff3rfLaA/Fv0pX5aqmBMpZ25U6SyIHHAGU5sKHDN/He06ftbhv2kiL/SvgzGbmyZOXd2k1IozTt1DbGHyidRZpnZ+NPXvRXh3LZw3jLUuBGXRVSvvI4rabqV+VJdH9wAegdA+5k2E4tPrlmff0T729wS9/EphT5kJDG5caIEuiO4B/Rjt8eCwI5lbP3u/e/ilDrRXvBg6hq/JYHqlaqa1LDZAl0VXA6dY5pJWCYE71vBn39W/3m3V80Ty6KnfmFqmF2r7UAFkSfR0928xzQfD+6lf2Xd4/eW23TZ5CV+Xfc4/UIir13x0PXGEdQlrH0dHxvmqy9wP9Wy8e8Mun01X5plmoFmjbq99rE8ZpB7UZ+yjrLNI6HfT33Tz2lLve2PHE9XRVzrPO02wq9RrCOA2obaPyWeMo0kJj6DvjwWTO16xztIJKPYgwThPgC9Y5pCU+lyVRKe6NHgmdUw8iS6IY6LLOIU3VBxzlc6FBM/WQwjg9HrgI6LTOIqPyPHBolkQ3WQdpNZW6AWGcvhO4GtjMOouMyHJgTpZEhX++WDPo8LsBWRLdBuwJ/ME6iwzbjcDe7VJoUKkbliVRBkynYHsRyzotAKL6c+rahg6/RyCM0y8C56BvikW1GjghS6LLrYNYUKlHKIzT2cC/AdsaR5HXWgx8PEuiB62DWNFMM0JZEi0EdgW8WTNccj3UnvE+s50LDZqpmyKM0w8BFwNbWmdpU/cBh2dJtNQ6SBFopm6CLIl+AeyEZu289QLfBPZQof9OM3WThXH6buACaofm0jo3ACdnSfRn6yBFo1K3QP1ur08A5wKTjOP45n7g81kSXW8dpKhU6hYK4/R11DYoPwWYYByn7J4DzgYuzpKo1zpMkanUOQjj9A3UZu0j0Bry4VpN7R73JEuiZ6zDlIFKnaMwTrcFPgd8CtjQNk3hPQ98C1iQJdGzxllKRaU2EMbpxsDR1B7EMNk4TtE8TG1556VZEq22DlNGKrWhME7XAz5Cbf/s3Y3jWOoDbgG+B1yTJZE2MRwFlbogwjjdGfgn4KNAaJsmN0upPezxyiyJHjfO4g2VuoDCON2XWsEPBTY3jtNsK4GfAFdkSbTMOoyPVOoCC+O0E9gfOAh4D7CjbaIRqVK7yeJm4CZgSZZE/baR/KZSl0gYp5OBA4CZ9ddU20SDWkatwDcDt2dJVOq9qcpGpS6xME4nAbtRW3f+6msa+S10+Ru1Ai8D7q2/lmVJVMlpfFkLldoz9eeWh9QKPpXaOfmrr9cP+PFEIFjj7W7A62Xg6QGvJ6idD68EHqN2Z1RW3+9bCkSlblP19ekB9RKrnP5QqUU8o/upRTyjUot4RqUW8YxKLeIZlVrEMyq1iGdUahHPqNQinlGpRTyjUot4RqUW8YxKLeIZlVrEMyq1iGdUahHPqNQinlGpRTyjUot4RqUW8YxKLeIZlVrEMyq1iGdUahHPqNQinlGpRTyjUot4RqUW8cz/Af2ziaJ+VxJaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam['v1'].value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanText(data):\n",
    "  text = re.sub('[^a-zA-Z]', ' ', data).lower()\n",
    "  return text\n",
    "\n",
    "spam.v2 = spam.v2.apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freemsg hey there darling it s been   week s now and no word back  i d like some fun you up for it still  tb ok  xxx std chgs to send         to rcv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.iloc[5]['v2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['freemsg',\n",
       " 'hey',\n",
       " 'there',\n",
       " 'darling',\n",
       " 'it',\n",
       " 's',\n",
       " 'been',\n",
       " 'week',\n",
       " 's',\n",
       " 'now',\n",
       " 'and',\n",
       " 'no',\n",
       " 'word',\n",
       " 'back',\n",
       " 'i',\n",
       " 'd',\n",
       " 'like',\n",
       " 'some',\n",
       " 'fun',\n",
       " 'you',\n",
       " 'up',\n",
       " 'for',\n",
       " 'it',\n",
       " 'still',\n",
       " 'tb',\n",
       " 'ok',\n",
       " 'xxx',\n",
       " 'std',\n",
       " 'chgs',\n",
       " 'to',\n",
       " 'send',\n",
       " 'to',\n",
       " 'rcv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 코드 코드\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "word_tokenize(spam.iloc[5]['v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point  crazy   available only in bugis n great world la e buffet    cine there got amore wat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don t think he goes to usf  he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>5567</td>\n",
       "      <td>1</td>\n",
       "      <td>this is the  nd time we have tried   contact u  u have won the       pound prize    claim is easy  call              now   only   p per minute  bt national rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>5568</td>\n",
       "      <td>0</td>\n",
       "      <td>will    b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>5569</td>\n",
       "      <td>0</td>\n",
       "      <td>pity    was in mood for that  so   any other suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>5570</td>\n",
       "      <td>0</td>\n",
       "      <td>the guy did some bitching but i acted like i d be interested in buying something else next week and he gave it to us for free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>5571</td>\n",
       "      <td>0</td>\n",
       "      <td>rofl  its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  v1  \\\n",
       "0     0      0    \n",
       "1     1      0    \n",
       "2     2      1    \n",
       "3     3      0    \n",
       "4     4      0    \n",
       "...  ..     ..    \n",
       "5164  5567   1    \n",
       "5165  5568   0    \n",
       "5166  5569   0    \n",
       "5167  5570   0    \n",
       "5168  5571   0    \n",
       "\n",
       "                                                                                                                                                                     v2  \n",
       "0     go until jurong point  crazy   available only in bugis n great world la e buffet    cine there got amore wat                                                       \n",
       "1     ok lar    joking wif u oni                                                                                                                                         \n",
       "2     free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s        \n",
       "3     u dun say so early hor    u c already then say                                                                                                                     \n",
       "4     nah i don t think he goes to usf  he lives around here though                                                                                                      \n",
       "...                                                             ...                                                                                                      \n",
       "5164  this is the  nd time we have tried   contact u  u have won the       pound prize    claim is easy  call              now   only   p per minute  bt national rate   \n",
       "5165  will    b going to esplanade fr home                                                                                                                               \n",
       "5166  pity    was in mood for that  so   any other suggestions                                                                                                           \n",
       "5167  the guy did some bitching but i acted like i d be interested in buying something else next week and he gave it to us for free                                      \n",
       "5168  rofl  its true to its name                                                                                                                                         \n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'as', 'of', 'too', \"wasn't\", 'more', 'now', \"you're\", 'into', \"you've\", 'her', 'an', \"you'll\", 'haven', 'hers', 'does', 'ourselves', 'because', 'while', \"it's\", 'those', 'shan', 'ma', 'is', 'itself', 'how', 'they', 'that', 'be', 'which', 'weren', 'each', 'its', 'again', \"haven't\", 'until', \"hadn't\", 'do', 'ours', 'whom', 'this', 'over', 'their', 'shouldn', 'themselves', 'and', 'for', 'about', 're', 'yourselves', 'own', 'd', 'having', 'am', 'out', 'with', 'off', 'had', 'myself', 'any', 'against', 'all', 'me', 'but', 'are', \"isn't\", 'below', 'has', 's', 'up', 'before', \"needn't\", 't', 'doesn', 'needn', 'him', 'm', \"shan't\", 'when', \"didn't\", 'aren', 'yours', 'theirs', 'them', 'from', \"doesn't\", 'i', 'will', 'same', 'other', 'should', 'doing', 'didn', 'isn', 'no', 'wouldn', \"she's\", 'she', 'your', 'who', 'yourself', 'by', 'mightn', 'under', 'won', 'mustn', 'we', 'just', 'why', 'the', \"weren't\", 've', \"wouldn't\", 'few', 'my', 'there', 'further', 'only', 'to', 'did', 'don', 'himself', 'on', \"won't\", 'his', 'than', 'ain', 'was', 'have', 'both', \"couldn't\", 'down', \"hasn't\", \"mightn't\", 'these', 'wasn', 'at', 'here', 'so', \"you'd\", 'it', 'o', \"should've\", 'were', 'during', \"that'll\", 'our', 'or', 'some', 'couldn', 'if', 'hadn', 'not', 'such', 'y', 'between', \"don't\", 'hasn', 'above', 'where', 'nor', 'a', 'most', 'through', \"mustn't\", 'being', 'once', 'll', 'then', \"aren't\", 'he', 'can', \"shouldn't\", 'what', 'herself', 'very', 'in', 'after', 'been', 'you'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = set(stopwords.words('english'))\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>5567</td>\n",
       "      <td>1</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>5568</td>\n",
       "      <td>0</td>\n",
       "      <td>[b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>5569</td>\n",
       "      <td>0</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>5570</td>\n",
       "      <td>0</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>5571</td>\n",
       "      <td>0</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  v1                                                 v2\n",
       "0         0   0  [go, jurong, point, crazy, available, bugis, n...\n",
       "1         1   0                     [ok, lar, joking, wif, u, oni]\n",
       "2         2   1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3         3   0      [u, dun, say, early, hor, u, c, already, say]\n",
       "4         4   0     [nah, think, goes, usf, lives, around, though]\n",
       "...     ...  ..                                                ...\n",
       "5164   5567   1  [nd, time, tried, contact, u, u, pound, prize,...\n",
       "5165   5568   0                    [b, going, esplanade, fr, home]\n",
       "5166   5569   0                          [pity, mood, suggestions]\n",
       "5167   5570   0  [guy, bitching, acted, like, interested, buyin...\n",
       "5168   5571   0                                 [rofl, true, name]\n",
       "\n",
       "[5169 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "wt = spam.copy()\n",
    "result = []\n",
    "for row in wt.v2:\n",
    "    tokenize = word_tokenize(row)\n",
    "    words = [word for word in tokenize if word not in sw]\n",
    "    result.append(words)\n",
    "    \n",
    "wt.v2 = result\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"treebank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tb_tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(tokenizer):\n",
    "  result=[]\n",
    "  for row in spam.v2:\n",
    "    tokenize = tokenizer.tokenize(row)\n",
    "    words = [word for word in tokenize if word not in sw] # 불용어 제거\n",
    "    result.append(words)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  v1                                                 v2\n",
      "0         0   0  [go, jurong, point, crazy, available, bugis, n...\n",
      "1         1   0                     [ok, lar, joking, wif, u, oni]\n",
      "2         2   1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
      "3         3   0      [u, dun, say, early, hor, u, c, already, say]\n",
      "4         4   0     [nah, think, goes, usf, lives, around, though]\n",
      "...     ...  ..                                                ...\n",
      "5164   5567   1  [nd, time, tried, contact, u, u, pound, prize,...\n",
      "5165   5568   0                    [b, going, esplanade, fr, home]\n",
      "5166   5569   0                          [pity, mood, suggestions]\n",
      "5167   5570   0  [guy, bitching, acted, like, interested, buyin...\n",
      "5168   5571   0                                 [rofl, true, name]\n",
      "\n",
      "[5169 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tb = spam.copy()\n",
    "tb.v2 = tokenizing(tb_tokenizer)\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  v1                                                 v2\n",
      "0         0   0  [go, jurong, point, crazy, available, bugis, n...\n",
      "1         1   0                     [ok, lar, joking, wif, u, oni]\n",
      "2         2   1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
      "3         3   0      [u, dun, say, early, hor, u, c, already, say]\n",
      "4         4   0     [nah, think, goes, usf, lives, around, though]\n",
      "...     ...  ..                                                ...\n",
      "5164   5567   1  [nd, time, tried, contact, u, u, pound, prize,...\n",
      "5165   5568   0                    [b, going, esplanade, fr, home]\n",
      "5166   5569   0                          [pity, mood, suggestions]\n",
      "5167   5570   0  [guy, bitching, acted, like, interested, buyin...\n",
      "5168   5571   0                                 [rofl, true, name]\n",
      "\n",
      "[5169 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "wp = spam.copy()\n",
    "wp.v2 = tokenizing(WordPunctTokenizer())\n",
    "print(wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_39660\\3281518368.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth',-1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenizer</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wordtokenize</td>\n",
       "      <td>freemsg hey there darling it s been   week s now and no word back  i d like some fun you up for it still  tb ok  xxx std chgs to send         to rcv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TreebankWordTokenizer</td>\n",
       "      <td>[freemsg, hey, darling, week, word, back, like, fun, still, tb, ok, xxx, std, chgs, send, rcv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WordPunctTokenizer</td>\n",
       "      <td>[freemsg, hey, darling, week, word, back, like, fun, still, tb, ok, xxx, std, chgs, send, rcv]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tokenizer  \\\n",
       "0  wordtokenize            \n",
       "1  TreebankWordTokenizer   \n",
       "2  WordPunctTokenizer      \n",
       "\n",
       "                                                                                                                                                 result  \n",
       "0  freemsg hey there darling it s been   week s now and no word back  i d like some fun you up for it still  tb ok  xxx std chgs to send         to rcv  \n",
       "1  [freemsg, hey, darling, week, word, back, like, fun, still, tb, ok, xxx, std, chgs, send, rcv]                                                        \n",
       "2  [freemsg, hey, darling, week, word, back, like, fun, still, tb, ok, xxx, std, chgs, send, rcv]                                                        "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "result = pd.DataFrame([['wordtokenize', wt.iloc[5]['v2']],\n",
    "                     ['TreebankWordTokenizer', tb.iloc[5]['v2']],\n",
    "                     ['WordPunctTokenizer', wp.iloc[5]['v2']]], columns = ['Tokenizer','result'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특수문자와 불용어를 제거한 후 tokenizing 은 유의미한 차이를 보이지 않는 듯 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "- 수업에서 다룬 임베딩 방법에는 One-hot encoding, CBOW, Skip-gram, GloVe, FastText가 있었습니다. 다양한 시도와 '비교' 결과를 함께 적어주세요! 파라미터를 조정해가는 과정도 해석에 도움이 될 수 있겠죠 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec의 주요 아이디어는 \"비슷한 분포를 가진 단어라면 비슷한 의미를 가질 것이다.\" 이다. 자주 등장하는 두 단어는 비슷한 의미를 가진다는 의미와 같다. 단어 사이의 유사함과 통사적 유사함을 정교하게 표현한다는 강점을 가지고 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip - Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [go, jurong, point, crazy, available, bugis, n, great, world, la, e, buffet, cine, got, amore, wat]                        \n",
       "1       [ok, lar, joking, wif, u, oni]                                                                                             \n",
       "2       [free, entry, wkly, comp, win, fa, cup, final, tkts, st, may, text, fa, receive, entry, question, std, txt, rate, c, apply]\n",
       "3       [u, dun, say, early, hor, u, c, already, say]                                                                              \n",
       "4       [nah, think, goes, usf, lives, around, though]                                                                             \n",
       "                             ...                                                                                                   \n",
       "5164    [nd, time, tried, contact, u, u, pound, prize, claim, easy, call, p, per, minute, bt, national, rate]                      \n",
       "5165    [b, going, esplanade, fr, home]                                                                                            \n",
       "5166    [pity, mood, suggestions]                                                                                                  \n",
       "5167    [guy, bitching, acted, like, interested, buying, something, else, next, week, gave, us, free]                              \n",
       "5168    [rofl, true, name]                                                                                                         \n",
       "Name: v2, Length: 5169, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\pc\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2022.6.15          |   py39haa95532_0         153 KB\n",
      "    conda-4.14.0               |   py39haa95532_0         937 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.6.1~ --> pkgs/main::ca-certificates-2022.07.19-haa95532_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2022.6.15~ --> pkgs/main/win-64::certifi-2022.6.15-py39haa95532_0\n",
      "  conda              conda-forge::conda-4.14.0-py39hcbf530~ --> pkgs/main::conda-4.14.0-py39haa95532_0\n",
      "  openssl            conda-forge::openssl-1.1.1q-h8ffe710_0 --> pkgs/main::openssl-1.1.1q-h2bbff1b_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2022.6.15    | 153 KB    |            |   0% \n",
      "certifi-2022.6.15    | 153 KB    | ########## | 100% \n",
      "certifi-2022.6.15    | 153 KB    | ########## | 100% \n",
      "\n",
      "conda-4.14.0         | 937 KB    |            |   0% \n",
      "conda-4.14.0         | 937 KB    | #########7 |  97% \n",
      "conda-4.14.0         | 937 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "! conda install -y gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토큰 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 정상 메일 토큰 빈도수\n",
    "ct_vector1 = CountVectorizer(max_features= 500, stop_words = 'english', lowercase= False)\n",
    "corpus_ham = sum(wp[wp.v1 == 0]['v2'], []) \n",
    "ct_ham = ct_vector1.fit_transform(corpus_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>gt</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>lt</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ok</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>got</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>know</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>like</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>good</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>come</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>ur</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>time</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "160  gt    288  \n",
       "245  lt    287  \n",
       "298  ok    255  \n",
       "155  got   227  \n",
       "212  know  225  \n",
       "229  like  222  \n",
       "153  good  215  \n",
       "67   come  212  \n",
       "450  ur    198  \n",
       "426  time  192  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ham = pd.DataFrame( {'word' : ct_vector1.get_feature_names(),\n",
    "                           'count' : ct_ham.sum(axis = 0).flat})\n",
    "count_ham.sort_values('count', ascending = False).head(10) # 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam 메일 토큰 빈도수\n",
    "ct_vector2 = CountVectorizer(max_features= 500, stop_words = 'english', lowercase= False)\n",
    "corpus_spam = sum(wp[wp.v1 == 1]['v2'], []) \n",
    "ct_spam = ct_vector2.fit_transform(corpus_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>free</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>txt</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>ur</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>stop</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>mobile</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>text</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>claim</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>reply</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>www</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>prize</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "144  free    197  \n",
       "437  txt     141  \n",
       "446  ur      119  \n",
       "396  stop    114  \n",
       "251  mobile  111  \n",
       "415  text    109  \n",
       "61   claim   96   \n",
       "345  reply   96   \n",
       "486  www     83   \n",
       "322  prize   82   "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_spam = pd.DataFrame( {'word' : ct_vector2.get_feature_names(),\n",
    "                           'count' : ct_spam.sum(axis = 0).flat})\n",
    "count_spam.sort_values('count', ascending = False).head(10) # 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(wp[wp.v1 == 1]['v2'],         # 리스트 형태의 데이터\n",
    "                 sg=1,         # 0: CBOW, 1: Skip-gram\n",
    "                 window=3,     # 고려할 앞뒤 폭(앞뒤 3단어)\n",
    "                 min_count=3,  # 사용할 단어의 최소 빈도(3회 이하 단어 무시)\n",
    "                 workers=4)    # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12697235,  0.17873126,  0.00917729,  0.04774045,  0.04983213,\n",
       "       -0.3183044 ,  0.06340779,  0.3627363 , -0.15260184, -0.13191845,\n",
       "       -0.04508005, -0.21811609,  0.03258903, -0.00776026,  0.10318357,\n",
       "       -0.11489538,  0.01857102, -0.20338188, -0.02372381, -0.34794012,\n",
       "        0.0759846 ,  0.09172342,  0.11160284, -0.09558625, -0.07979911,\n",
       "        0.01351385, -0.14549081, -0.13445719, -0.18485789,  0.02839618,\n",
       "        0.20579396,  0.01613657,  0.05163672, -0.08718101, -0.1392553 ,\n",
       "        0.18269157,  0.01795943, -0.1227628 , -0.05834493, -0.24545982,\n",
       "        0.01107112, -0.2154894 , -0.1155944 , -0.08909006,  0.17233887,\n",
       "       -0.10991798, -0.14960937,  0.03219679,  0.16723125,  0.11586914,\n",
       "        0.10903287, -0.1612806 ,  0.04058929,  0.0306169 , -0.09393346,\n",
       "        0.11316695,  0.03703046,  0.02580187, -0.2559138 ,  0.06118606,\n",
       "        0.03958989, -0.01570959, -0.01404729, -0.15912132, -0.2548095 ,\n",
       "        0.04643291,  0.05343216,  0.1475917 , -0.27400813,  0.20167056,\n",
       "       -0.08806373,  0.06910041,  0.20795195,  0.02375374,  0.158016  ,\n",
       "        0.04609252, -0.05567769, -0.07568779, -0.16485225,  0.01095457,\n",
       "       -0.04479373, -0.06274648, -0.163387  ,  0.315679  , -0.04922067,\n",
       "       -0.03185305, -0.0425237 ,  0.21561022,  0.22183569,  0.04081018,\n",
       "        0.22519046,  0.11233827, -0.04141232,  0.11747391,  0.30567938,\n",
       "        0.2260004 ,  0.09557275, -0.15243235,  0.07362075, -0.15046419],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['free']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'txt'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"free txt ut stop mobile text claim reply www prize\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shit', 0.9984922409057617),\n",
       " ('guys', 0.9983488917350769),\n",
       " ('place', 0.9983454942703247),\n",
       " ('believe', 0.9983223676681519),\n",
       " ('fine', 0.9983163475990295),\n",
       " ('need', 0.998307466506958),\n",
       " ('someone', 0.9982812404632568),\n",
       " ('missed', 0.9982679486274719),\n",
       " ('sir', 0.9982408881187439),\n",
       " ('tot', 0.9982295036315918)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('talk', 0.9968039393424988),\n",
       " ('friend', 0.9967077970504761),\n",
       " ('able', 0.9966264963150024),\n",
       " ('room', 0.9966209530830383),\n",
       " ('asked', 0.9965845942497253),\n",
       " ('want', 0.9965538382530212),\n",
       " ('someone', 0.9965472221374512),\n",
       " ('text', 0.9965046644210815),\n",
       " ('gonna', 0.9964979887008667),\n",
       " ('cool', 0.9964866042137146)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['mobile', 'free'], negative=['msg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ham 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec(wp[wp.v1 == 0]['v2'],         # 리스트 형태의 데이터\n",
    "                 sg=1,         # 0: CBOW, 1: Skip-gram\n",
    "                 window=3,     # 고려할 앞뒤 폭(앞뒤 3단어)\n",
    "                 min_count=3,  # 사용할 단어의 최소 빈도(3회 이하 단어 무시)\n",
    "                 workers=4)    # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1443505 ,  0.20394184,  0.07682936,  0.03954577,  0.13750094,\n",
       "       -0.3645187 ,  0.16928954,  0.40799648, -0.11899674, -0.1311487 ,\n",
       "       -0.0536454 , -0.21566293, -0.07567759,  0.0831868 ,  0.06097643,\n",
       "       -0.14391026, -0.01299365, -0.15194145,  0.00999578, -0.4197288 ,\n",
       "        0.09025447,  0.1592725 ,  0.07344285, -0.10049437, -0.06827156,\n",
       "        0.00423986, -0.16068932, -0.11644737, -0.15143156,  0.006872  ,\n",
       "        0.21309324,  0.07517155,  0.09136862, -0.13171464, -0.05964   ,\n",
       "        0.19532524,  0.05206435, -0.15981022, -0.16918407, -0.3886908 ,\n",
       "       -0.0346077 , -0.18204083, -0.0322253 ,  0.02765786,  0.13075146,\n",
       "       -0.07280753, -0.11469225, -0.03836975,  0.13274479,  0.12872842,\n",
       "        0.0895739 , -0.215694  , -0.02176245, -0.03556813, -0.07683107,\n",
       "        0.12459389,  0.11901166, -0.01152744, -0.26687524,  0.09790961,\n",
       "        0.03397292,  0.01984393, -0.05374684, -0.03103813, -0.23643617,\n",
       "        0.04347331,  0.083359  ,  0.1292469 , -0.21213764,  0.20457567,\n",
       "       -0.16746503,  0.05765475,  0.20744294, -0.16746582,  0.12799786,\n",
       "        0.02959708,  0.02965332, -0.10901482, -0.1567007 ,  0.09920461,\n",
       "       -0.00566244,  0.0306142 , -0.14467889,  0.24804083,  0.00855686,\n",
       "        0.00890525, -0.03271325,  0.27538893,  0.22363043,  0.14968058,\n",
       "        0.26411745,  0.16669722,  0.03077086,  0.09296996,  0.33668527,\n",
       "        0.25824532,  0.05626851, -0.15293342,  0.13762653, -0.02845554],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.doesnt_match(\"gt lt ok got know like good come ur time\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('god', 0.9985902905464172),\n",
       " ('gonna', 0.9984800815582275),\n",
       " ('person', 0.9984670877456665),\n",
       " ('change', 0.9984626173973083),\n",
       " ('left', 0.9984471201896667),\n",
       " ('special', 0.9984450340270996),\n",
       " ('shit', 0.9984412789344788),\n",
       " ('home', 0.9984278082847595),\n",
       " ('havent', 0.9984269142150879),\n",
       " ('lar', 0.99842369556427)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv.most_similar('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*skip gram을 활용하여 spam 빈도수 상위 10개 단어 중 가장 유사하지 않은 단어 txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'free'와 가장 유사한 단어\n",
    "\n",
    "[('shit', 0.9984922409057617),\n",
    "\n",
    " ('guys', 0.9983488917350769),\n",
    " \n",
    " ('place', 0.9983454942703247),\n",
    " \n",
    " ('believe', 0.9983223676681519),\n",
    " \n",
    " ('fine', 0.9983163475990295),\n",
    " \n",
    " ('need', 0.998307466506958),\n",
    " \n",
    " ('someone', 0.9982812404632568),\n",
    " \n",
    " ('missed', 0.9982679486274719),\n",
    " \n",
    " ('sir', 0.9982408881187439),\n",
    " \n",
    " ('tot', 0.9982295036315918)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ham에서 가장 연관이 없는 단어는 'gt'\n",
    "\n",
    "'ok'와 가장 유사도가 높은 단어들 10개\n",
    "\n",
    "[('god', 0.9985902905464172),\n",
    "\n",
    " ('gonna', 0.9984800815582275),\n",
    " \n",
    " ('person', 0.9984670877456665),\n",
    " \n",
    " ('change', 0.9984626173973083),\n",
    " \n",
    " ('left', 0.9984471201896667),\n",
    " \n",
    " ('special', 0.9984450340270996),\n",
    " \n",
    " ('shit', 0.9984412789344788),\n",
    " \n",
    " ('home', 0.9984278082847595),\n",
    " \n",
    " ('havent', 0.9984269142150879),\n",
    " \n",
    " ('lar', 0.99842369556427)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip-gram 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. spam 메일에서 많이 사용되는 단어들을 보면 need : 무엇이 필요합니다, someonem : 누군가가 위험에 빠졌다. , missed : 무엇인가 잊으셨다. , sir : 고객께서는~ 는 등 스팸 메일을 구분하는데 합리적인 단어들이 있다.\n",
    "\n",
    "\n",
    "2. ham 에서는 ok, gonna, shit, havent 등 줄임말이나 컴퓨터가 아닌 인간이 텍스트로 쳤을 법한 단어들이 있는 것으로 보아 단체 스팸 메일이라고 보기 힘든 단어들이 있다.\n",
    "\n",
    "\n",
    "-한계 : 가장 유사하지 않는 단어로 뽑힌 txt와 gt는 spam 과 ham 을 구분하기에는 크게 의미 있지는 않아보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Bag Of Word(CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Word2Vec(wp[wp.v1 == 1]['v2'],         # 리스트 형태의 데이터\n",
    "                 sg=0,         # 0: CBOW, 1: Skip-gram\n",
    "                 window=3,     # 고려할 앞뒤 폭(앞뒤 3단어)\n",
    "                 min_count=3,  # 사용할 단어의 최소 빈도(3회 이하 단어 무시)\n",
    "                 workers=4)    # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04899706,  0.08751968,  0.00543651,  0.01689396,  0.01165799,\n",
       "       -0.17804685,  0.03880432,  0.214122  , -0.0569067 , -0.06772427,\n",
       "       -0.00833088, -0.10876993, -0.01424619, -0.00094331,  0.0467719 ,\n",
       "       -0.05459564,  0.01318529, -0.08884684, -0.00528288, -0.1871343 ,\n",
       "        0.03333976,  0.04733661,  0.05313151, -0.05537691, -0.04830177,\n",
       "        0.01052547, -0.08197225, -0.08177868, -0.09773952,  0.00282098,\n",
       "        0.12024564,  0.01060125,  0.03878962, -0.05439466, -0.05359166,\n",
       "        0.11253292,  0.02871179, -0.06539643, -0.03939414, -0.13729575,\n",
       "        0.01729326, -0.0948604 , -0.07342607, -0.03718002,  0.08715764,\n",
       "       -0.05607364, -0.08486367,  0.01042789,  0.08325735,  0.05615759,\n",
       "        0.04962488, -0.07143588,  0.02147228,  0.02951938, -0.03939703,\n",
       "        0.06679582,  0.05545926,  0.01085535, -0.09107533,  0.03903873,\n",
       "        0.00858373,  0.01531649, -0.03157279, -0.07993756, -0.11540367,\n",
       "        0.05298875,  0.04392067,  0.06114257, -0.13001806,  0.11044212,\n",
       "       -0.06689774,  0.02540871,  0.10219285, -0.01054284,  0.08261479,\n",
       "        0.02364859,  0.00510048, -0.03543282, -0.10281536,  0.02092509,\n",
       "       -0.03200321, -0.00156569, -0.10014845,  0.15328246, -0.03532325,\n",
       "        0.01515234, -0.01667348,  0.11315147,  0.1226475 ,  0.03125672,\n",
       "        0.128708  ,  0.06877735, -0.02073227,  0.03576375,  0.15747143,\n",
       "        0.12328432,  0.04498699, -0.10542437,  0.02579038, -0.06318641],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv['free']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reply'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.doesnt_match(\"free txt ut stop mobile text claim reply www prize\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('call', 0.9950637817382812),\n",
       " ('txt', 0.993674099445343),\n",
       " ('p', 0.993118941783905),\n",
       " ('u', 0.9929732084274292),\n",
       " ('www', 0.9929603338241577),\n",
       " ('text', 0.9925583004951477),\n",
       " ('ur', 0.9924313426017761),\n",
       " ('service', 0.9921772480010986),\n",
       " ('cash', 0.9920705556869507),\n",
       " ('claim', 0.9918743371963501)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.most_similar('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gift', 0.7601175308227539),\n",
       " ('inc', 0.7552603483200073),\n",
       " ('see', 0.7517488598823547),\n",
       " ('nokia', 0.7505438327789307),\n",
       " ('want', 0.7502791881561279),\n",
       " ('msg', 0.7498944997787476),\n",
       " ('camcorder', 0.7497456669807434),\n",
       " ('points', 0.7487547993659973),\n",
       " ('new', 0.7482020854949951),\n",
       " ('waiting', 0.7467624545097351)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.most_similar('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ham 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Word2Vec(wp[wp.v1 == 0]['v2'],         # 리스트 형태의 데이터\n",
    "                 sg=1,         # 0: CBOW, 1: Skip-gram\n",
    "                 window=3,     # 고려할 앞뒤 폭(앞뒤 3단어)\n",
    "                 min_count=3,  # 사용할 단어의 최소 빈도(3회 이하 단어 무시)\n",
    "                 workers=4)    # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.54401571e-01,  2.04134196e-01,  7.89765045e-02,  3.53333764e-02,\n",
       "        1.06312148e-01, -3.58860224e-01,  1.96674779e-01,  4.00581598e-01,\n",
       "       -1.38293400e-01, -1.15760490e-01, -4.14281264e-02, -2.03555122e-01,\n",
       "       -9.91389081e-02,  7.37232044e-02,  4.08410877e-02, -1.40083313e-01,\n",
       "       -1.45338485e-02, -1.86228499e-01, -2.44670053e-04, -3.97594780e-01,\n",
       "        7.10906610e-02,  1.78308964e-01,  1.04171343e-01, -8.29384625e-02,\n",
       "       -4.26469892e-02, -8.92305002e-03, -1.57449916e-01, -1.10313378e-01,\n",
       "       -1.56483725e-01,  8.03323742e-03,  2.27580786e-01,  5.75542599e-02,\n",
       "        1.21415488e-01, -1.01168513e-01, -9.13109183e-02,  2.06002802e-01,\n",
       "        9.89786536e-02, -1.59464866e-01, -1.89905345e-01, -3.84407908e-01,\n",
       "       -5.17883971e-02, -1.58695355e-01, -4.36115973e-02,  4.81113531e-02,\n",
       "        1.36939928e-01, -6.39539063e-02, -9.60881412e-02, -3.45331840e-02,\n",
       "        1.16793439e-01,  1.19701251e-01,  9.63019207e-02, -2.05732450e-01,\n",
       "       -3.41446213e-02, -4.77371030e-02, -9.75704566e-02,  1.05112165e-01,\n",
       "        1.36170879e-01, -2.02667005e-02, -2.61674434e-01,  8.46845135e-02,\n",
       "        4.96441051e-02, -2.30291709e-02, -4.60291542e-02, -4.00385410e-02,\n",
       "       -2.37085894e-01,  3.04938871e-02,  9.21110511e-02,  1.35583580e-01,\n",
       "       -2.46069416e-01,  1.85401097e-01, -1.86826706e-01,  7.76732564e-02,\n",
       "        2.11190894e-01, -1.54349536e-01,  1.44323111e-01,  4.36023846e-02,\n",
       "       -1.22835943e-02, -8.48173499e-02, -1.67905450e-01,  9.64282900e-02,\n",
       "        1.71681903e-02,  3.17413323e-02, -1.51542574e-01,  2.64569819e-01,\n",
       "       -4.04546643e-03,  1.52321858e-02, -2.75067519e-02,  2.70368129e-01,\n",
       "        2.08965123e-01,  1.48106292e-01,  2.34056115e-01,  1.98303089e-01,\n",
       "        1.16078984e-02,  9.31284651e-02,  3.29911768e-01,  2.46199206e-01,\n",
       "        4.12497446e-02, -1.56875268e-01,  1.73992351e-01, -2.67037973e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.wv['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.wv.doesnt_match(\"gt lt ok got know like good come ur time\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('special', 0.9984639286994934),\n",
       " ('havent', 0.9984007477760315),\n",
       " ('lar', 0.998380720615387),\n",
       " ('person', 0.9983792304992676),\n",
       " ('need', 0.9983651041984558),\n",
       " ('someone', 0.9983472228050232),\n",
       " ('plan', 0.9983054995536804),\n",
       " ('friend', 0.998300313949585),\n",
       " ('probably', 0.9982932806015015),\n",
       " ('able', 0.9982566237449646)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.wv.most_similar('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CBOW을 활용하여 spam 빈도수 상위 10개 단어 중 가장 유사하지 않은 단어 reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spam 중 'free'와 가장 유사한 단어\n",
    "\n",
    "[('call', 0.9950637817382812),\n",
    "\n",
    " ('txt', 0.993674099445343),\n",
    " \n",
    " ('p', 0.993118941783905),\n",
    " \n",
    " ('u', 0.9929732084274292),\n",
    " \n",
    " ('www', 0.9929603338241577),\n",
    " \n",
    " ('text', 0.9925583004951477),\n",
    " \n",
    " ('ur', 0.9924313426017761),\n",
    " \n",
    " ('service', 0.9921772480010986),\n",
    " \n",
    " ('cash', 0.9920705556869507),\n",
    " \n",
    " ('claim', 0.9918743371963501)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CBOW을 활용하여 ham 빈도수 상위 10개 단어 중 가장 유사하지 않은 단어 gt - skip 과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ham 에서 'ok'와 가장 유사한 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('special', 0.9984639286994934),\n",
    "\n",
    " ('havent', 0.9984007477760315),\n",
    " \n",
    " ('lar', 0.998380720615387),\n",
    " \n",
    " ('person', 0.9983792304992676),\n",
    " \n",
    " ('need', 0.9983651041984558),\n",
    " \n",
    " ('someone', 0.9983472228050232),\n",
    " \n",
    " ('plan', 0.9983054995536804),\n",
    " \n",
    " ('friend', 0.998300313949585),\n",
    " \n",
    " ('probably', 0.9982932806015015),\n",
    " \n",
    " ('able', 0.9982566237449646)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. spam에는 응답을 바란다는 메시지가 들어갈 가능성이 크다고 판단되어 CBOW의 reply가 조금더 합리적이라고 판단됨\n",
    "\n",
    "2. txt,call,cash, claim, www 등 일반적인 메시지에 담기지 않는 링크나 전화 파일 명등이 이상하게 배치되어 있는 것을 확인할 수 있고 주목할만한 점으로는 cash와 같이 직접적인 spam메일성 메시지도 포함되어있을 뿐만 아니라 skip-gram에서 판단되었던 구어체 'gonna', 'havent' 와 같이 ur 이 들어있다는 점에서 url과 혼용성을 구분해봐야겠지만 나름 신기한 유사도를 보여준다.\n",
    "\n",
    "3. skip-gram과 비슷한 유사도의 단어들이 대부분인반면 probably,able등과 같이 가능성을 나타내는 단어들이 눈에 띄는것으로 보아 아마도 지인사이의 메일에는 구어체의 형식이 확실히 많이 쓰이는 듯하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 부록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genism 으로 학습된 단어 임베딩을 케라스에서 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS, EMB_DIM = model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embedding(input_dim=NUM_WORDS, output_dim=EMB_DIM,\n",
    "                trainable=False, weights=[model.wv.vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Sequential()\n",
    "net.add(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = model.wv.index_to_key.index('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.17100777,  0.22741504,  0.1415306 ,  0.09078712,  0.13565189,\n",
       "        -0.3124442 ,  0.15087669,  0.3452993 , -0.20554623, -0.08115021,\n",
       "         0.10307804, -0.37570322,  0.12328479,  0.01569165, -0.01478906,\n",
       "        -0.15338697, -0.01407131, -0.36315718, -0.07180541, -0.2618075 ,\n",
       "         0.09475271,  0.12284674,  0.096205  , -0.19126713, -0.15548222,\n",
       "         0.06995478, -0.13768817, -0.11744229, -0.15492031, -0.04076614,\n",
       "         0.31780586, -0.03640383,  0.164043  , -0.04313457, -0.07690811,\n",
       "         0.34024894,  0.0645443 , -0.22640206, -0.15790546, -0.37338832,\n",
       "        -0.09059562, -0.21744114, -0.12313711,  0.01098755,  0.11266868,\n",
       "        -0.06786525, -0.02781567, -0.13342474,  0.00813981,  0.09535321,\n",
       "         0.01803571, -0.1154272 , -0.16399351, -0.02158661, -0.14056829,\n",
       "         0.15666394,  0.07962795, -0.01083533, -0.14108612,  0.00414327,\n",
       "        -0.07731659, -0.00915988,  0.06944455,  0.01070126, -0.2169706 ,\n",
       "         0.26310647,  0.03318975,  0.15881616, -0.2278557 ,  0.13021062,\n",
       "        -0.14601158,  0.09773567,  0.31715897,  0.04030796,  0.2504783 ,\n",
       "        -0.0290696 , -0.08418668, -0.17019345, -0.31925607, -0.0610422 ,\n",
       "        -0.15529662, -0.0475994 , -0.15672515,  0.12618686,  0.0315997 ,\n",
       "        -0.07560213, -0.00987419,  0.16165908,  0.36752036, -0.0191504 ,\n",
       "         0.06190259,  0.08110759,  0.09621852,  0.03610809,  0.39616624,\n",
       "         0.16423662,  0.20833696, -0.19927901,  0.12383393,  0.0431865 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'free'의 임베딩된 벡터 값을 확인해보면 gensim에서와 같다는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 임베딩 사용하기\n",
    "https://code.google.com/archive/p/word2vec 에서 1천억 단어 규모의 구글 뉴스 데이터로 300만개의 단어의 임베딩을 미리 학습시킨 Word2Vec 임베딩을 다운 받았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
